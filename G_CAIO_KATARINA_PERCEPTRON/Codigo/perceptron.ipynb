{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos do Perceptron: Uma Abordagem Prática\n",
    "\n",
    "## Sumário\n",
    "1. [Introdução ao Perceptron](#intro)\n",
    "2. [Problemas Lógicos OR e AND](#or-and)\n",
    "3. [O Problema XOR e suas Implicações](#xor)\n",
    "\n",
    "Este notebook apresenta uma introdução detalhada ao Perceptron, um dos primeiros modelos de redes neurais artificiais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução ao Perceptron <a id='intro'></a>\n",
    "\n",
    "### 1.1 O que é um Perceptron?\n",
    "\n",
    "O Perceptron é um modelo matemático de um neurônio biológico, proposto por Frank Rosenblatt em 1958. É a forma mais simples de uma rede neural artificial que pode ser usada para classificação binária e serve como bloco fundamental para redes neurais artificiais. Ele simula o comportamento de um neurônio biológico com um modelo computacional simples, sendo a base para redes neurais mais complexas.\n",
    "\n",
    "### 1.2 Estrutura Básica\n",
    "\n",
    "Um Perceptron consiste em:\n",
    "1. Entradas ($x_1, x_2, ..., x_n$)\n",
    "2. Pesos ($w_1, w_2, ..., w_n$)\n",
    "3. Bias ($b$)\n",
    "4. Função de ativação (degrau)\n",
    "\n",
    "primeiro ele recebe as entradas, multiplica cada entrada pelo seu peso correspondente, soma todos os resultados e adiciona o bias e aplica uma função de ativaçao.\n",
    "\n",
    "\n",
    "### 1.3 Fórmulas Matemáticas\n",
    "\n",
    "A saída do Perceptron é calculada da seguinte forma:\n",
    "\n",
    "1. Soma ponderada: $z = \\sum_{i=1}^n w_i x_i + b$\n",
    "2. Função de ativação: $f(z) = \\begin{cases} 1 & \\text{se } z \\geq 0 \\\\ 0 & \\text{se } z < 0 \\end{cases}$\n",
    "\n",
    "### 1.4 Algoritmo de Aprendizagem\n",
    "\n",
    "O algoritmo de treinamento segue os seguintes passos:\n",
    "1. Inicialização dos pesos e bias com valores aleatórios\n",
    "2. Para cada exemplo de treinamento:\n",
    "   - Calcular a saída prevista do perceptron, compara com o valor real e atualiza os pesos se houver erro.\n",
    "   - Atualizar os pesos: $w_i = w_i + \\alpha(y - \\hat{y})x_i$\n",
    "   - Atualizar o bias: $b = b + \\alpha(y - \\hat{y})$\n",
    "\n",
    "onde $\\alpha$ é a taxa de aprendizagem, $y$ é o valor real e $\\hat{y}$ é a previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
    "        # Aqui defino os parâmetros iniciais do meu perceptron\n",
    "        self.learning_rate = learning_rate  # Taxa de aprendizado - controla o tamanho dos ajustes\n",
    "        self.n_iterations = n_iterations  # Máximo de vezes que vou passar pelos dados\n",
    "        self.weights = None  # Ainda não sei quantos pesos vou precisar\n",
    "        self.bias = None  # Viés também será definido depois\n",
    "        self.errors_ = []  # Aqui vou guardar meus erros para acompanhar o aprendizado\n",
    "        self.weights_history = []  # Histórico dos pesos pra ver como evoluem\n",
    "        self.bias_history = []  # Histórico do bias também\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Primeiro entendo o formato dos meus dados\n",
    "        n_samples, n_features = X.shape \n",
    "        \n",
    "        # Inicializo meus pesos como zeros (um para cada característica)\n",
    "        # Começo com bias zero também\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Registro esse estado inicial no histórico\n",
    "        self.weights_history.append(self.weights.copy())\n",
    "        self.bias_history.append(self.bias)\n",
    "        \n",
    "        # Passo pelos dados várias vezes\n",
    "        for _ in range(self.n_iterations):\n",
    "            errors = 0  # Contador de erros nesta rodada\n",
    "            \n",
    "            # Para cada exemplo e seu rótulo verdadeiro\n",
    "            for xi, target in zip(X, y):\n",
    "                # Primeiro tento prever o rótulo com meus pesos atuais\n",
    "                prediction = self.predict_one(xi)\n",
    "                \n",
    "                # Vejo o quanto errei (diferença entre o real e minha previsão)\n",
    "                error = target - prediction\n",
    "                \n",
    "                # Se errei, ajusto meus pesos e bias\n",
    "                # Quanto maior o learning_rate, maior o ajuste\n",
    "                self.weights += self.learning_rate * error * xi\n",
    "                self.bias += self.learning_rate * error\n",
    "                \n",
    "                # Se houve erro, contabilizo\n",
    "                errors += int(error != 0)\n",
    "            \n",
    "            # Depois de passar por todos exemplos, guardo quantos errei\n",
    "            self.errors_.append(errors)\n",
    "            \n",
    "            # Também guardo como estão meus pesos e bias agora\n",
    "            self.weights_history.append(self.weights.copy())\n",
    "            self.bias_history.append(self.bias)\n",
    "            \n",
    "            # Se não errei nenhum, posso parar antes!\n",
    "            if errors == 0:\n",
    "                break\n",
    "        \n",
    "        return self  # Retorno eu mesmo, agora treinado\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        # Calculo a ativação: produto interno entre pesos e entradas + bias\n",
    "        activation = np.dot(x, self.weights) + self.bias\n",
    "        \n",
    "        # Decisão: se >=0 retorna 1, senão 0 (função degrau)\n",
    "        return 1 if activation >= 0 else 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Para prever vários exemplos, aplico predict_one em cada um\n",
    "        return np.array([self.predict_one(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Perceptron tenta encontrar um hiperplano (uma reta, no caso 2D) que separe os dados em duas classes (geralmente 0 e 1, ou -1 e 1).\n",
    "O Perceptron é um dos algoritmos mais simples de aprendizado de máquina supervisionado, sendo a base para redes neurais artificiais. Ele é um classificador linear binário, ou seja, separa dados em duas classes usando uma fronteira de decisão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problemas Lógicos OR e AND <a id='or-and'></a>\n",
    "\n",
    "Vamos implementar e visualizar o Perceptron resolvendo os problemas lógicos OR e AND."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos datasets\n",
    "X_logic = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_or = np.array([0, 1, 1, 1])  # OR\n",
    "y_and = np.array([0, 0, 0, 1])  # AND\n",
    "\n",
    "def plot_decision_boundary(X, y, perceptron, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Plot os pontos\n",
    "    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', marker='o', label='0')\n",
    "    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', marker='x', label='1')\n",
    "    \n",
    "    # Criar grade para plotar a fronteira de decisão\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    \n",
    "    # Calcular a fronteira de decisão\n",
    "    Z = np.array([perceptron.predict_one([x1, x2]) \n",
    "                  for x1, x2 in zip(xx.ravel(), yy.ravel())])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plotar a fronteira de decisão\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Treinar e visualizar OR\n",
    "perceptron_or = Perceptron(learning_rate=0.1, n_iterations=100)\n",
    "perceptron_or.fit(X_logic, y_or)\n",
    "plot_decision_boundary(X_logic, y_or, perceptron_or, 'Perceptron - OR Logic Gate')\n",
    "\n",
    "# Treinar e visualizar AND\n",
    "perceptron_and = Perceptron(learning_rate=0.1, n_iterations=100)\n",
    "perceptron_and.fit(X_logic, y_and)\n",
    "plot_decision_boundary(X_logic, y_and, perceptron_and, 'Perceptron - AND Logic Gate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicação da Fronteira de Decisão (OR)\n",
    "A fronteira de decisão para o problema OR é uma linha reta que separa:\n",
    "\n",
    "Classe 0: apenas o ponto (0,0)\n",
    "\n",
    "Classe 1: pontos (0,1), (1,0) e (1,1)\n",
    "\n",
    "\n",
    "\n",
    "Explicação da Fronteira de Decisão (AND)\n",
    "Para o problema AND:\n",
    "\n",
    "Classe 0: pontos (0,0), (0,1) e (1,0)\n",
    "\n",
    "Classe 1: apenas o ponto (1,1)\n",
    "\n",
    "A fronteira de decisão é uma linha com inclinação diferente da do OR, posicionada de forma que apenas (1,1) fique na região positiva. Os pesos aprendidos refletem a necessidade de ambas as entradas serem 1 para a saída ser 1.\n",
    "\n",
    "\n",
    "O Perceptron consegue resolver perfeitamente problemas linearmente separáveis como OR e AND\n",
    "\n",
    "A fronteira de decisão é uma linha reta cuja equação depende dos pesos aprendidos\n",
    "\n",
    "Para o OR, a linha precisa separar (0,0) dos demais pontos\n",
    "\n",
    "Para o AND, a linha precisa separar (1,1) dos demais pontos\n",
    "\n",
    "O algoritmo converge rapidamente (em poucas épocas) para esses problemas simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_training(X_logic, y, model, title):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    def update(i):\n",
    "        ax.clear()\n",
    "        ax.scatter(X_logic[:, 0], X_logic[:, 1], c=y, s=100, cmap='viridis')\n",
    "        ax.set_xlim(-0.5, 1.5)\n",
    "        ax.set_ylim(-0.5, 1.5)\n",
    "        ax.set_title(f\"{title}\\nÉpoca: {i}, Erros: {model.errors_[i] if i < len(model.errors_) else 0}\")\n",
    "        \n",
    "        if i < len(model.weights_history):\n",
    "            w = model.weights_history[i]\n",
    "            b = model.bias_history[i]\n",
    "            if w[1] != 0:\n",
    "                x1 = np.array([-0.5, 1.5])\n",
    "                x2 = -(w[0] * x1 + b) / w[1]\n",
    "                ax.plot(x1, x2, 'r-', linewidth=2)\n",
    "        \n",
    "        ax.axhline(y=0, color='k', linestyle='--', alpha=0.2)\n",
    "        ax.axvline(x=0, color='k', linestyle='--', alpha=0.2)\n",
    "        ax.grid(True)\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=len(model.weights_history), interval=500)\n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml())\n",
    "\n",
    "# Animação para OR\n",
    "animate_training(X_logic, y_or, perceptron_or, \"Treinamento Perceptron - OR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
