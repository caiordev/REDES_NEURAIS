{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos do Perceptron: Uma Abordagem Prática\n",
    "\n",
    "## Sumário\n",
    "1. [Introdução ao Perceptron](#intro)\n",
    "2. [Problemas Lógicos OR e AND](#or-and)\n",
    "3. [O Problema XOR e suas Implicações](#xor)\n",
    "\n",
    "Este notebook apresenta uma introdução detalhada ao Perceptron, um dos primeiros modelos de redes neurais artificiais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução ao Perceptron <a id='intro'></a>\n",
    "\n",
    "### 1.1 O que é um Perceptron?\n",
    "\n",
    "O Perceptron é um modelo matemático de um neurônio biológico, proposto por Frank Rosenblatt em 1958. É a forma mais simples de uma rede neural artificial que pode ser usada para classificação binária e serve como bloco fundamental para redes neurais artificiais. Ele simula o comportamento de um neurônio biológico com um modelo computacional simples, sendo a base para redes neurais mais complexas.\n",
    "\n",
    "### 1.2 Estrutura Básica\n",
    "\n",
    "Um Perceptron consiste em:\n",
    "1. Entradas ($x_1, x_2, ..., x_n$)\n",
    "2. Pesos ($w_1, w_2, ..., w_n$)\n",
    "3. Bias ($b$)\n",
    "4. Função de ativação (degrau)\n",
    "\n",
    "primeiro ele recebe as entradas, multiplica cada entrada pelo seu peso correspondente, soma todos os resultados e adiciona o bias e aplica uma função de ativaçao.\n",
    "\n",
    "\n",
    "### 1.3 Fórmulas Matemáticas\n",
    "\n",
    "A saída do Perceptron é calculada da seguinte forma:\n",
    "\n",
    "1. Soma ponderada: $z = \\sum_{i=1}^n w_i x_i + b$\n",
    "2. Função de ativação: $f(z) = \\begin{cases} 1 & \\text{se } z \\geq 0 \\\\ 0 & \\text{se } z < 0 \\end{cases}$\n",
    "\n",
    "### 1.4 Algoritmo de Aprendizagem\n",
    "\n",
    "O algoritmo de treinamento segue os seguintes passos:\n",
    "1. Inicialização dos pesos e bias com valores aleatórios\n",
    "2. Para cada exemplo de treinamento:\n",
    "   - Calcular a saída prevista do perceptron, compara com o valor real e atualiza os pesos se houver erro.\n",
    "   - Atualizar os pesos: $w_i = w_i + \\alpha(y - \\hat{y})x_i$\n",
    "   - Atualizar o bias: $b = b + \\alpha(y - \\hat{y})$\n",
    "\n",
    "onde $\\alpha$ é a taxa de aprendizagem, $y$ é o valor real e $\\hat{y}$ é a previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, n_iterations=100):\n",
    "        # Aqui defino os parâmetros iniciais do meu perceptron\n",
    "        self.learning_rate = learning_rate  # Taxa de aprendizado - controla o tamanho dos ajustes\n",
    "        self.n_iterations = n_iterations  # Máximo de vezes que vou passar pelos dados\n",
    "        self.weights = None  # Ainda não sei quantos pesos vou precisar\n",
    "        self.bias = None  # Viés também será definido depois\n",
    "        self.errors_ = []  # Aqui vou guardar meus erros para acompanhar o aprendizado\n",
    "        self.weights_history = []  # Histórico dos pesos pra ver como evoluem\n",
    "        self.bias_history = []  # Histórico do bias também\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Primeiro entendo o formato dos meus dados\n",
    "        n_samples, n_features = X.shape \n",
    "        \n",
    "        # Inicializo meus pesos como zeros (um para cada característica)\n",
    "        # Começo com bias zero também\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Registro esse estado inicial no histórico\n",
    "        self.weights_history.append(self.weights.copy())\n",
    "        self.bias_history.append(self.bias)\n",
    "        \n",
    "        # Passo pelos dados várias vezes\n",
    "        for _ in range(self.n_iterations):\n",
    "            errors = 0  # Contador de erros nesta rodada\n",
    "            \n",
    "            # Para cada exemplo e seu rótulo verdadeiro\n",
    "            for xi, target in zip(X, y):\n",
    "                # Primeiro tento prever o rótulo com meus pesos atuais\n",
    "                prediction = self.predict_one(xi)\n",
    "                \n",
    "                # Vejo o quanto errei (diferença entre o real e minha previsão)\n",
    "                error = target - prediction\n",
    "                \n",
    "                # Se errei, ajusto meus pesos e bias\n",
    "                # Quanto maior o learning_rate, maior o ajuste\n",
    "                self.weights += self.learning_rate * error * xi\n",
    "                self.bias += self.learning_rate * error\n",
    "                \n",
    "                # Se houve erro, contabilizo\n",
    "                errors += int(error != 0)\n",
    "            \n",
    "            # Depois de passar por todos exemplos, guardo quantos errei\n",
    "            self.errors_.append(errors)\n",
    "            \n",
    "            # Também guardo como estão meus pesos e bias agora\n",
    "            self.weights_history.append(self.weights.copy())\n",
    "            self.bias_history.append(self.bias)\n",
    "            \n",
    "            # Se não errei nenhum, posso parar antes!\n",
    "            if errors == 0:\n",
    "                break\n",
    "        \n",
    "        return self  # Retorno eu mesmo, agora treinado\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        # Calculo a ativação: produto interno entre pesos e entradas + bias\n",
    "        activation = np.dot(x, self.weights) + self.bias\n",
    "        \n",
    "        # Decisão: se >=0 retorna 1, senão 0 (função degrau)\n",
    "        return 1 if activation >= 0 else 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Para prever vários exemplos, aplico predict_one em cada um\n",
    "        return np.array([self.predict_one(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Perceptron tenta encontrar um hiperplano (uma reta, no caso 2D) que separe os dados em duas classes (geralmente 0 e 1, ou -1 e 1).\n",
    "O Perceptron é um dos algoritmos mais simples de aprendizado de máquina supervisionado, sendo a base para redes neurais artificiais. Ele é um classificador linear binário, ou seja, separa dados em duas classes usando uma fronteira de decisão linear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
